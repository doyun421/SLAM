Humanoid Robot Industry


      Data Scientist : Data Modeling with Statistics and Mathmetics for predicting the future data. 
                       Choosing proper Data Model and Proper Pytorch or Tensorflow or Nxins or other Library for taking proper Data handling tools such as pandas, numpy, image decoder, image encoder as python
                       But it needs to check the ROS2 program for checking lidar sensor data and handling these data as input value for data analysis. 
                       AI for robotics service can be choosen with baby care or others. 
                       competition for robotics company
                       accuracy competition as robotics field. 
                       high accuracy should have to be dependent on only the number of data?
                       fast and accuracy was the point 
                      
                       accuracy should have be the number of percentage of the test bed. 
                       not a train bed. 


                        data for image for robotics 
                        and the data for numbers as lidar counts. 
                        ultra sound frequency data as sound for detecting the noise of voice or environment sounds. 

                        for detecting the thermal of human or other data

                                          so it needs what is the domain it is not a data itself.



                        Data examples as robotics 
                                                       : lidar, raser, radar, mic, rf signal for communicating with other devices such as phone for remote controlling, 
                                                         camera for visioning, 

                        Image Data from camera when they only using delivery robot is they have same specity as load or restaurant or residential apaprtment building 
                                                                                    and also korea has buildings which are crowded. 
                                                                                    but the building have similar look so it's hard to distinguish
                                                                                    so same but similar very it require qutie sophisticated process. 
                                                                                    it needs detail process modelling. 
                        
                                                                                    not a 1st order function but those like 4th order function for the detail but it could take more than 2 sec for each images. 
                                                                                    so it's really hard to processing for real business. 
                                                                                    so it's the purpose to find proper model against each domain industry.

                                                                                    
                                                                                    also it is very core to choose correct library against each domain such as pytorch, etc. or keras. 

                                                                                    Nginx, 



                                                                                                      Keras : needed for smaller datasets ex. which don't have to waste any resource or any data storage like as small test bed or just a toy.
                                                                                                      PyTorch : can be less than TensorFlow but it should be cheaper than TensorFlow as cost or time consumption. 






오늘 최대한 다 끝내두고 관련 포트폴리오 작성하고 바로 지원하면 될 거 같아!

안녕하세요!
저는 현재 엔비디아로 이직을 하고자 열정적으로 준비하고 있는 원도윤 입니다.
저에 대해 말씀드려도 괜찮으신지요!

저의 열정에 대하여 말씀드리고 싶습니다.
저는 통계와 수학을 너무 좋아하여 초중고 내내 일등급을 유지해 왔으며
수학 경시대회도 세 번 정도 참가 하였습니다.

대학교 진학 시에 
세상의 존재하는 모든 기기들의 하드웨어 메커닉 부분에서 
기계어 단계에서 전기 신호까지 섭렵하길 바라왔고 
모든 회로와 통신의 단계를 알아감에도 
수학적인 부분의 갈증을 느끼어 
통계를 자주 사용할 수 있는
첫본째로 
데이터 아날리틱스로 기술 연구소에 취직하게 되었습니다.
통계를 6개월 과정으로 패스트 캠퍼스라는 온라인 학습을 회사에서 지원해주어
기본적인 pandas, numpy 등 
tensorflow, pytorch, nginx, keras 라이브러리를
학습했으며 이에 더하여 SVM, regression, linear 등의 
그래프와 수식의 정의를 손으로 익혔습니다.

그럼에도 
해외 지식이 더욱 탐나게 되어 
외국계이며 data를 이미지 중심으로 처리할 수 있는
	두번 째 회사에luxolis 회사에 취업하게
됩니다. 
이 과정에서 저는 face recognition을 tensorflow를 활용하여
cnn이라는 가벼운 모델을 사용하여 accuracy를 97%까지 끌어올렸습니다.
face detection은 단순히 배경과 얼굴을 구별하는 과정이어서 
단 몇 장의 사진으로도 augmentation을 통한 데이타 증량으로 
학습이 accuracy 98%이상 끌어 올렸습니다.이는 명암만 존재하여
색채가 명확하지 않은 상황에도 가능했지만 face recognition의 경우
명암만 존재하는 어두운 날씨 또는 마스크에 의한 영향을 모두 고려 해야 했기 때문에
haas라는 방식으로 encoding 값을 다르게 저장하는 방식을 선택하게
됩니다. 얼굴의 포인트를 입술 눈 코 윤곽 등과 같이 따로 지정하여
포인트 별로 해당 데이터 값을 cnn으로 압축하여 저장하면서 
parameter cnn 내부의 convolution layer를 증가하거나
zero pending 을 통해 값을 증가 시켜 최대한 명확학 encoding 값을 도출함으로 인해
가장 accuracy를 높이는 방안을 채택하였습니다.
그 결과 97%라는 결과를 얻었습니다.
하지만 위는 그 당시의 직원분들의 데이터를 테스트로 하여 얻은 결과이기에 
데이터가 증가 할 수 록 안정하다고 말할 수 는 없었습니다.

여기서 저는 데이터의 양 또는 관리 저장 공간의 유무,
다양한 모델의 실험 가능성, 논문을 현실화할 수 있는 진취적이고 
라즈베리 파이 4로만 모든 걸 해결해야 하는 상황에 하드웨어 
고성능의 갈증을 느끼게 됩니다.

그리하여 
computer vision의 현재 가장 많은 데이터를 가지며 
가장 활발한 자율주행차량 회사인 yandex (현 avride)에 들어가게 됩니다.
정말 행복한 기억 뿐이었던 전 직장에서
저는 정말로 많은 경험을 하였습니다.

제일 간단한 배달 로봇 하드웨어 수리 및 점검, 자율주행차량의 
하드웨어 점검 및 수리 보조 등을 하였스며 이 과정에서 회로 부분까지 모두 
분해하여 로봇의 고장의 원인과 트랜지스터의 결함 판결 그 외에
휠, IMU, gnss, lidar, camera, xavier까지 모두 혼자서 
고치는 경험을 하며 그 입출력 데이터를 직접 보고 측정하며 
결함을 판단하고 고치고 이를 직접 서비스에 매니저라는 칭호로 
담당하기 까지 하였습니다.

GPS, Gnss로 오는 데이터의 차이 그리고 현장에서 얻어야 하는 
rtk의 데이터 한국 지형상 러시아 또는 두바이 와의 다른 지형상의 특징
계절상의 특징을 통해 서비스를 직접 적용하는데에 필요한 데이터와 
기술적 준비 등을 경험하였습니다. 또한, 제가 정말로 원했던 data analytic을
스스로 요일 별 한국인의 배달 건수를 python3와 간단한 건수 정리로 
금>목>화>월>수 라는 결과를 도출하여 가장 리더이신 velery 님께 요청드렸고 
그 결과 배달 건수를 늘 염려하던 리더 분들에게 조금이나마 예측 가능한 
불안을 드려 안정감을 드린 기억이 있습니다. 이를 토대로 
날씨와 가격의 상관도를 조사하라는 본부를 받아 요기요 배달의 민족 쿠팡 이츠의 어플리케이션을 
통한 비가 올 때 1000~3000원의 추가 비용이
발생함을 확인하고 전달드렸습니다. 

하지만
이러한 raw data를 라이다의 입출력 신호와 point cloud 및 
camera 안의 아이들의 움직임 또는 차량의 접촉 등을 볼 때마다 
단순히 raw data만 보기에 두뇌가 너무 간지러웠습니다.

특히나 자율주행차량의 데모 패드를 통한 motion planning의 prediction 값과
한국의 도로 주행의 특성상 어린이 보호구역의 단점을 커버하는 방향등
camera 및 lidar calibration을 위한 

lens distortion 을 공부하였고 
위 공부에 집중하여 이와 관련된
직무로 이직하고자 법인장님께 차근히 
data scientist로의 열말을 내비춰 
코드에 대한 접근을 부탁하였지만 
법인장님께서도 노력하여 본사에 부탁하여 주셨지만
권한이 열리지 않기도 하였으며 

논문을 보고 실행하는 것을 좋아하는 
열망을 위해 이직을 선택하게 되었습니다.
이전 회사는 특히나 러시아 분들의 강한 기술력과 
꼼꼼하고 빠른 실행력으로 많은 것을 본 받았기에
퇴사하기 더더욱 힘들었습니다.

하지만 
제가 정말로 원하는 것은 
끊임없는 수학적 문제해결과 
예측을 통한 예방을 극도로 좋아함을 
깨닳았습니다.

그리하여 
현재도 끊임없이 부족한 학력이지만 
기회의 문을 두드리고 있습니다!

대학원 진학이 도움이 될 듯 하여 
대학원 진학 또한 지원을 진행 중에 있습니다.

저는 
계속해서 도전해서 제가 원하는 안전한 세상을 만들고 싶습니다.
AI와 robot 및 self driving car 등을 접해왔지만 
가장 중요한 것은 높은 가능성의 예측을 가장 효율적인 라이브러리 및 툴들로 
조력자 처럼 빠르고 리소스 낭비
없이 계산해주는 CPU 및 GPU 그리고 그외 accuralator 등(lidar, gps, gnss, camera, rf signals from devices, radar)
과 같이 편리한 모뎀들을 활용하여 가장 신기술적으로 적합하게 
테트리스 처럼 맞춰 나가고 싶습니다.

저는 통계를 정말로 사랑합니다. 
수학 만큼 저의 두뇌를 두드려 주고 
저를 안정화 시켜주는 분야는 없습니다.

또한,
이전 회사들에서 부족했던 영어회화가 자연스레 학습되어서 
업무에 지장되지 않고 원활하게 소통이 가능한 상황입니다.
현재도 모든 문서는 깃허브에 영어로만 작성 중에 있습니다.




