Humanoid Robot Industry


      Data Scientist : Data Modeling with Statistics and Mathmetics for predicting the future data. 
                       Choosing proper Data Model and Proper Pytorch or Tensorflow or Nxins or other Library for taking proper Data handling tools such as pandas, numpy, image decoder, image encoder as python
                       But it needs to check the ROS2 program for checking lidar sensor data and handling these data as input value for data analysis. 
                       AI for robotics service can be choosen with baby care or others. 
                       competition for robotics company
                       accuracy competition as robotics field. 
                       high accuracy should have to be dependent on only the number of data?
                       fast and accuracy was the point 
                      
                       accuracy should have be the number of percentage of the test bed. 
                       not a train bed. 


                        data for image for robotics 
                        and the data for numbers as lidar counts. 
                        ultra sound frequency data as sound for detecting the noise of voice or environment sounds. 

                        for detecting the thermal of human or other data

                                          so it needs what is the domain it is not a data itself.



                        Data examples as robotics 
                                                       : lidar, raser, radar, mic, rf signal for communicating with other devices such as phone for remote controlling, 
                                                         camera for visioning, 

                        Image Data from camera when they only using delivery robot is they have same specity as load or restaurant or residential apaprtment building 
                                                                                    and also korea has buildings which are crowded. 
                                                                                    but the building have similar look so it's hard to distinguish
                                                                                    so same but similar very it require qutie sophisticated process. 
                                                                                    it needs detail process modelling. 
                        
                                                                                    not a 1st order function but those like 4th order function for the detail but it could take more than 2 sec for each images. 
                                                                                    so it's really hard to processing for real business. 
                                                                                    so it's the purpose to find proper model against each domain industry.

                                                                                    
                                                                                    also it is very core to choose correct library against each domain such as pytorch, etc. or keras. 

                                                                                    Nginx, 



                                                                                                      Keras : needed for smaller datasets ex. which don't have to waste any resource or any data storage like as small test bed or just a toy.
                                                                                                      PyTorch : can be less than TensorFlow but it should be cheaper than TensorFlow as cost or time consumption. 






오늘 최대한 다 끝내두고 관련 포트폴리오 작성하고 바로 지원하면 될 거 같아!

안녕하세요!
저는 현재 Data Anlytics의 모든 준비를 하고 있는 원도윤 입니다!
저에 대해 말씀드려도 괜찮으신지요.
저의 열정에 대하여 말씀드리고 싶습니다.

첫번째로,
유년시절 부터 통계와 수학을 너무 좋아하여 
초중고등학생 대부분을 일등급을 유지해 왔으며
수학 경시대회도 상장이 남아있는 것은 하나이지만 
그 외에도 여러번의 대회에 참가하여 상을 얻었습니다.

두번째로,
대학교 진학 시 저의 모든 신호들에 대한 열정을 말씀드리고자 합니다!
세상의 존재하는 모든 기기들의 하드웨어 메커닉 부분에서 
기계어 단계에서 전기 신호까지 섭렵하도록 하였습니다.
이 과정에서 Labview를 통한 이미지 코딩과 수천만원에 다르는 
smith chart를 물리적 기기가 아닌 신호적 연결로 기본적인 
소자회로를 아이디아 내고 구현해 내어 두 유도체 기판을 활용한 무선전력통신을 
해당 수업 반에서 유일하게 성공해낸 팀이 되었습니다.
이로 인해 LED 불빛 조절을 성공하였습니다.
 
세번째로,
이러한 기초 학문 뒤에
모든 회로와 통신의 단계를 알아감에
수학 부분의 갈증을 느끼어 
통계를 자주 사용할 수 있는
데이터 애널리틱스로 기술 연구소에 취직하게 되었습니다.
감사하게도 회사에서 6개월 과정으로 패스트 캠퍼스라는 
온라인 학습을 회사에서 지원해주어 
기본적인 pandas, numpy 등 python package를 통해
csv 파일에 담겨진 데이터들을 다룰 수 있게 되었습니다.

이에 더하여 RandomForest, SVM, Regression, Linear Regression 등의 
그래프와 수식의 정의를 손으로 익혔습니다.
이 과정에서 복잡한 수식이 굉장한 흥미로 다가왔습니다.

네번째로,
이를 현실에서 사용해 보고 싶었습니다.
이를 가능하게 해주신 Luxolis 회사를 통해
Tensorflow, Pytorch, Nginx, Keras 라이브러리를
학습하며 각기 다른 차이점(training 속도, Resource 사용정도)를
구분하게 되었습니다.

이 과정에서 저는 face recognition을 tensorflow를 활용하여
CNN이라는 기초적인 이미지 모델링을 사용하여 accuracy를 97%까지 끌어올렸습니다.
face detection은 단순히 배경과 얼굴을 구별하는 과정이어서 
단 몇 장의 사진으로도 augmentation을 통한 데이터 증량으로 
학습이 accuracy 98% 이상 끌어 올렸습니다.

이는 명암만 존재하여 색채가 명확하지 않은 상황에도 가능했지만 face recognition의 경우
명암만 존재하는 어두운 날씨 또는 마스크에 의한 영향을 모두 고려 해야 했기 때문에
Haas라는 방식으로 encoding 값을 다르게 저장하는 방식을 선택하게
됩니다. 얼굴의 포인트를 입술 눈 코 윤곽 등과 같이 따로 지정하여
포인트 별로 해당 데이터 값을 CNN으로 계산 및 압축하여 저장하면서 
cnn 내부의 parameter인 convolution layer를 증가하거나
zero pedding 을 통해 이미지 사이즈를 통일시켜 최대한 명확한 
encoding 값을 이미지 resizing 없이 도출함으로 인해
가장 accuracy를 높이는 방안을 채택하였습니다.

하지만 위는 그 당시의 직원분들의 데이터를 테스트로 하여 얻은 결과이기에 
데이터가 증가 할 수 록 안정하다고 말할 수 는 없었습니다.
여기서 저는 데이터의 양 또는 데이터의 관리 저장 공간의 유무,
다양한 모델의 실험 가능성, 논문을 현실화할 수 있는 프로젝트, 
라즈베리 파이 4로만 모든 걸 해결해야 하는 상황에 하드웨어 
고성능의 갈증을 느끼게 됩니다.

그리하여
다섯번째로,
computer vision의 현재 가장 많은 데이터를 가지며 
가장 활발한 자율주행차량 회사인 
yandex (현 avride)에 들어가게 됩니다.
정말 행복한 기억 뿐이었던 전 직장에서
저는 정말로 많은 경험을 하였습니다.

제일 간단한 배달 로봇 하드웨어 수리 및 점검, 
자율주행차량의 하드웨어 점검 및 수리 보조 등을 하였으며
이 과정에서 회로 부분까지 모두 분해하여 로봇의 고장의 원인과 
트랜지스터의 결함 판결 
그 외에 Wheel, IMU, gnss, lidar, camera, xavier까지 
모두 스스로 외국 동료분들의 도움으로 
고치는 경험을 하며 그 입출력 데이터를 직접 보고 측정하며 
결함을 판단하고 고치고 이를 직접 서비스에 매니저라는 칭호로 
담당하기 까지 하였습니다.
가장 마음에 남는 기억은 8번대의 로봇을 생과 사에서 
살려낸 기억입니다. 수리하는 과정에서 
모든 부분을 테스트하며 러시아 support engineer분과 
수도 없는 시뮬레이션 그리고 강한 살림의 열망으로 살려냈었습니다.
너무나도 뜻 깊었고 저에게 불가능이란 없다는 것을 알게 해준 계기가 되어
모든 분야에서도 절대로 포기하지 않고 끝끝내 이뤄내도록 하는 자신감을 갖게되었습니다.

GPS, Gnss로 오는 데이터의 차이 그리고 현장에서 얻어야 하는 
rtk의 차이, 한국 지형상 러시아 또는 두바이 와의 다른 지형상의 특징
계절상의 특징을 통해 서비스를 직접 적용하는데에 필요한 데이터와 
기술적 준비 등을 경험하였습니다. 

또한, 
제가 정말로 원했던 data analytic을
스스로 요일 별 한국인의 배달 건수 기반으로 python3에
의해 금>목>화>월>수 라는 결과를 도출하여 가장 팀의 리더님께 요청드렸으며
그 결과 배달 건수를 늘 염려하던 리더 분들에게 조금이나마 예측 가능한 
안정감을 드린 기억이 있습니다. 
이를 토대로 날씨와 가격의 상관도를 조사하라는 본부를 받아 
요기요, 배달의 민족, 쿠팡 이츠의 어플리케이션을 
통한 비가 올 때 추가 구체적 비용이
발생함을 확인하고 전달드렸습니다. 

하지만
이러한 raw data들을 접할 때 마다
예를 들어 라이다의 입출력 신호와 point cloud 및 
camera 안의 아이들의 움직임 또는 차량의 접촉 등을 볼 때마다 
두뇌가 너무 간지러웠습니다.

특히나 자율주행차량의 데모 패드를 통한 
motion planning의 prediction 값과
한국의 도로 주행의 특성상 어린이 보호구역의 단점을 커버하는 방향 등
camera 및 lidar calibration을 위한 
lens distortion 을 공부하였고 

위 공부에 집중하여 이와 관련된
직무로 이직하고자 법인장님께 차근히 
data scientist로의 열망을 내비춰 
코드에 대한 접근을 부탁하였지만 
법인장님께서도 노력하여 본사에 부탁하여 주셨지만
권한이 열리지 않았으며 이는 
열망을 위해 이직을 선택으로 향하게 되었습니다.
이전 회사는 러시아 분들의 강한 기술력과 
꼼꼼하고 빠른 실행력으로 많은 것을 본 받았기에
퇴사하기 더더욱 힘들었습니다.

하지만 
제가 정말로 원하는 것은 
끊임없는 수학적 문제해결과 
예측을 통한 예방임을 명확히 깨닳음에 
나아감에 두려움이 보이지 않았습니다.

그리하여 
현재에도 끊임없이 부족한 경력과 학력이지만
기회의 문을 두드리고 있습니다!

저는 
계속해서 도전해서 제가 원하는 안전한 세상을 만들고 싶습니다.
AI와 robot 및 self driving car 등을 접해왔지만 
가장 중요한 것은 높은 가능성의 예측을 가장 효율적인 라이브러리 및 툴들로 
리소스 낭비 없이 계산해주는 CPU 및 GPU 그리고 
그 외 sensor 등(lidar, gps, gnss, camera, rf signals from devices, radar)
과 같이 편리한 모뎀들을 활용하여 가장 신기술적으로 적합하게 
테트리스 처럼 맞춰 나가고 싶습니다.

저는 통계를 정말로 사랑합니다. 
수학 만큼 저의 두뇌를 두드려 주고 
저를 안정화 시켜주는 분야는 없습니다.

또한,
이전 회사들에서 부족했던 영어회화가 자연스레 학습되어서 
업무에 지장되지 않고 원활하게 소통이 가능한 상황입니다.
현재도 모든 문서는 GitHub 또한 영어로만 작성 중에 있습니다.

혹시 제게 추천해 주실 수 있는
모델이나 교육 과정 또는 경력이 떠오르신다면! 
아낌없이 말씀해 주시면 바로 실행하고 싶습니다 :) 

엔비디아에 제가 필요한 직무가 있다면 언제든지 
연락을 주신다면 늘 준비된 자세로 기다리고 있겠습니다!




